{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.SemEvalData import SemEvalData\n",
    "from src.JigsawData import JigsawData\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import AveragePooling1D, Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed, Dropout, Flatten, SpatialDropout1D\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from src.Attention import AttentionLayer as Attention\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from src.preprocessing import get_embeddings_index, get_embeddings_matrix, getSpansByToxicWords\n",
    "from keras import Sequential\n",
    "from test_sentence import preprocess_lstm, test_lime, vectorize, Transform, getPredictedWordsFromSentence, test_lime_2\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##set to .env\n",
    "MAX_FEATURES = 200000 # maximum number of unique words that should be included in the tokenized word index\n",
    "MAX_WORD_NUM = 40     # maximum number of letters in sentence?\n",
    "EMBED_SIZE = 50  ## same value as in dimension of glove\n",
    "VAL_SPLIT = 0.2  \n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/patrycja/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "train_data_semeval = SemEvalData(MAX_WORD_NUM)\n",
    "train_data_semeval.load_data(\"data/tsd_train.csv\")\n",
    "train_df_preprocessed = train_data_semeval.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxic_words</th>\n",
       "      <th>original_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>diff</th>\n",
       "      <th>toxicity_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>because hes a moron and a bigot. its not any m...</td>\n",
       "      <td>1</td>\n",
       "      <td>[moron, bigot]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "      <td>[because hes a moron and a bigot., its not any...</td>\n",
       "      <td>[10, 36]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>how about we stop protecting idiots and let na...</td>\n",
       "      <td>1</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "      <td>[how about we stop protecting idiots and let n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>if people  were  smart, they would  boycott th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "      <td>[if people  were  smart, they would  boycott t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>trump claimed that russia will never invade th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "      <td>[trump claimed that russia will never invade t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>as long as your willing to pay a lot more for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "      <td>[as long as your willing to pay a lot more for...</td>\n",
       "      <td>[148]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>[129, 130, 131, 132, 133, 134]</td>\n",
       "      <td>but ... trumps not bluffing. hes prepared to g...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>But ... Trump's not bluffing. He's prepared to...</td>\n",
       "      <td>[but ... trumps not bluffing., hes prepared to...</td>\n",
       "      <td>[13, 32, 151, 159, 166]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>[126, 127, 128, 129, 130, 131]</td>\n",
       "      <td>cant believe the limited knowledge of this art...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>Can't believe the limited knowledge of this Ar...</td>\n",
       "      <td>[cant believe the limited knowledge of this ar...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>[24, 25, 26, 27, 28, 29]</td>\n",
       "      <td>i think it conservative idiots who cannot reac...</td>\n",
       "      <td>1</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>I think it conservative idiots who cannot reac...</td>\n",
       "      <td>[i think it conservative idiots who cannot rea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>youre an id*ot...go away.</td>\n",
       "      <td>1</td>\n",
       "      <td>[youre an id*ot]</td>\n",
       "      <td>You're an id*ot...Go away.</td>\n",
       "      <td>[youre an id*ot...go away.]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>[136, 137, 138, 139, 140, 141]</td>\n",
       "      <td>unless there is wording in the employment cont...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>Unless there is wording in the employment cont...</td>\n",
       "      <td>[unless there is wording in the employment con...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 spans  \\\n",
       "0             [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                             [29, 30, 31, 32, 33, 34]   \n",
       "2                       [166, 167, 168, 169, 170, 171]   \n",
       "3                             [87, 88, 89, 90, 91, 92]   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "685                     [129, 130, 131, 132, 133, 134]   \n",
       "686                     [126, 127, 128, 129, 130, 131]   \n",
       "687                           [24, 25, 26, 27, 28, 29]   \n",
       "688  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "689                     [136, 137, 138, 139, 140, 141]   \n",
       "\n",
       "                                                  text  toxicity  \\\n",
       "0    because hes a moron and a bigot. its not any m...         1   \n",
       "1    how about we stop protecting idiots and let na...         1   \n",
       "2    if people  were  smart, they would  boycott th...         1   \n",
       "3    trump claimed that russia will never invade th...         1   \n",
       "4    as long as your willing to pay a lot more for ...         0   \n",
       "..                                                 ...       ...   \n",
       "685  but ... trumps not bluffing. hes prepared to g...         1   \n",
       "686  cant believe the limited knowledge of this art...         1   \n",
       "687  i think it conservative idiots who cannot reac...         1   \n",
       "688                          youre an id*ot...go away.         1   \n",
       "689  unless there is wording in the employment cont...         1   \n",
       "\n",
       "          toxic_words                                      original_text  \\\n",
       "0      [moron, bigot]  Because he's a moron and a bigot. It's not any...   \n",
       "1            [idiots]  How about we stop protecting idiots and let na...   \n",
       "2            [idiots]  If people  were  smart, they would  Boycott th...   \n",
       "3            [stupid]  Trump Claimed that Russia will never invade th...   \n",
       "4                  []  As long as your willing to pay a lot more for ...   \n",
       "..                ...                                                ...   \n",
       "685          [stupid]  But ... Trump's not bluffing. He's prepared to...   \n",
       "686          [stupid]  Can't believe the limited knowledge of this Ar...   \n",
       "687          [idiots]  I think it conservative idiots who cannot reac...   \n",
       "688  [youre an id*ot]                         You're an id*ot...Go away.   \n",
       "689          [stupid]  Unless there is wording in the employment cont...   \n",
       "\n",
       "                                             sentences  \\\n",
       "0    [because hes a moron and a bigot., its not any...   \n",
       "1    [how about we stop protecting idiots and let n...   \n",
       "2    [if people  were  smart, they would  boycott t...   \n",
       "3    [trump claimed that russia will never invade t...   \n",
       "4    [as long as your willing to pay a lot more for...   \n",
       "..                                                 ...   \n",
       "685  [but ... trumps not bluffing., hes prepared to...   \n",
       "686  [cant believe the limited knowledge of this ar...   \n",
       "687  [i think it conservative idiots who cannot rea...   \n",
       "688                        [youre an id*ot...go away.]   \n",
       "689  [unless there is wording in the employment con...   \n",
       "\n",
       "                        diff          toxicity_sentence  \n",
       "0                   [10, 36]                 [1.0, 0.0]  \n",
       "1                         []                 [1.0, 0.0]  \n",
       "2                         []                      [1.0]  \n",
       "3                         []                      [1.0]  \n",
       "4                      [148]            [0.0, 0.0, 0.0]  \n",
       "..                       ...                        ...  \n",
       "685  [13, 32, 151, 159, 166]  [0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "686                      [3]                 [0.0, 1.0]  \n",
       "687                       []                      [1.0]  \n",
       "688                      [3]                      [1.0]  \n",
       "689                       []       [1.0, 0.0, 0.0, 0.0]  \n",
       "\n",
       "[690 rows x 8 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = []\n",
    "labels = []\n",
    "texts = []\n",
    "sent_lens = []\n",
    "sent_nums = []\n",
    "\n",
    "##tokenize words\n",
    "len_tr = len(train_df_preprocessed)\n",
    "# result = train_df_preprocessed.append(extra_train_df, ignore_index=True, sort=False)\n",
    "result = train_df_preprocessed\n",
    "train_data = {\n",
    "    'sentence':  result.sentences.sum(),\n",
    "    'toxicity_sentence': result.toxicity_sentence.sum()\n",
    "        }\n",
    "\n",
    "train_df = pd.DataFrame (train_data, columns = ['sentence','toxicity_sentence'])\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for i in train_df.sentence:\n",
    "    sentences.append(nltk.word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter token that are not alphabetic\n",
    "sentences_filter=[]\n",
    "for i, w in enumerate(sentences):\n",
    "    sentences[i] = [word for word in sentences[i] if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter stop words\n",
    "#nltk.download('stopwords')\n",
    "#from nltk.corpus import stopwords\n",
    "#stop_words = stopwords.words('english')\n",
    "#for i, w in enumerate(sentences):\n",
    "#    sentences[i] = [w for w in sentences[i] if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [x for x in sentences if x!=[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save toknizer to file so that it could be used again\n",
    "import pickle\n",
    "\n",
    "# saving\n",
    "\n",
    "# with open('tokenizer_nn.pickle', 'wb') as handle:\n",
    "\n",
    "#    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES,lower=True, split=\" \")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "word_counts = tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True, limit = 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "vocabulary_size=min(len(word_index)+1,MAX_FEATURES)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    if i>=MAX_FEATURES:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=0\n",
    "        absent_words+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = np.zeros((len(sentences), MAX_WORD_NUM), dtype='int32')\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for k, word in enumerate(sentence):\n",
    "        try:\n",
    "            if k<MAX_WORD_NUM and tokenizer.word_index[word]<MAX_FEATURES:\n",
    "                data_index[i,k] = tokenizer.word_index[word]\n",
    "        except:\n",
    "            #print(word)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  67  118    4  150    2    4  877    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  54   18   65   55 1909   84    8    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  52   44   37  133  878   81    2  139  879 1202  101 1910    3    1\n",
      "  1911 1203    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  37   45  129 1912   35 1204   13    1  880 1205    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  36   26   71  676   19   49 1206   12  561 1913   29   19   10   18\n",
      "   676   34 1914 1915   39   12   66  134 1916  278    1   81   13    4\n",
      "  1207    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(data_index[:5])\n",
    "indices = np.arange(data_index.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data_index[indices].copy()\n",
    "##IMPORTANT\n",
    "data = data.astype(np.float32)\n",
    "labels = train_df.toxicity_sentence.iloc[indices]\n",
    "# labels = labels.astype(np.float32)\n",
    "nb_validation_samples = int(VAL_SPLIT * data.shape[0])\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = np.vstack(labels[:-nb_validation_samples])\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = np.vstack(labels[-nb_validation_samples:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_softmax_train = np.zeros((y_train.shape[0], 2))\n",
    "y_softmax_val = np.zeros((y_val.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, y_softmax_train.shape[0]):\n",
    "    if y_train[i] == 0:\n",
    "        y_softmax_train[i][0] = 1\n",
    "    else :\n",
    "        y_softmax_train[i][1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, y_softmax_val.shape[0]):\n",
    "    if y_val[i] == 0:\n",
    "        y_softmax_val[i][0] = 1\n",
    "    else :\n",
    "        y_softmax_val[i][1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import backend as T\n",
    "\n",
    "class TemporalMeanPooling(Layer):\n",
    "    \"\"\"\n",
    "This is a custom Keras layer. This pooling layer accepts the temporal\n",
    "sequence output by a recurrent layer and performs temporal pooling,\n",
    "looking at only the non-masked portion of the sequence. The pooling\n",
    "layer converts the entire variable-length hidden vector sequence\n",
    "into a single hidden vector, and then feeds its output to the Dense\n",
    "layer.\n",
    "\n",
    "input shape: (nb_samples, nb_timesteps, nb_features)\n",
    "output shape: (nb_samples, nb_features)\n",
    "\"\"\"\n",
    "def __init__(self, **kwargs):\n",
    "    super(TemporalMeanPooling, self).__init__(**kwargs)\n",
    "    self.supports_masking = True\n",
    "    self.input_spec = [InputSpec(ndim=3)]\n",
    "\n",
    "def get_output_shape_for(self, input_shape):\n",
    "    return (input_shape[0], input_shape[2])\n",
    "\n",
    "def call(self, x, mask=None): #mask: (nb_samples, nb_timesteps)\n",
    "    if mask is None:\n",
    "        mask = T.mean(T.ones_like(x), axis=-1)\n",
    "    ssum = T.sum(x,axis=-2) #(nb_samples, np_features)\n",
    "    mask = T.cast(mask,T.floatx())\n",
    "    rcnt = T.sum(mask,axis=-1,keepdims=True) #(nb_samples)\n",
    "    return ssum/rcnt\n",
    "    #return rcnt\n",
    "\n",
    "def compute_mask(self, input, mask):\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 300)           1388400   \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "temporal_mean_pooling_35 (Te (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_final (Dense)          (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,549,002\n",
      "Trainable params: 1,549,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index)+1 ,EMBEDDING_DIM,weights=[embedding_matrix], input_length=MAX_WORD_NUM, trainable= True, name='embedding'))\n",
    "model.add(LSTM(100,dropout=0.7, recurrent_dropout = 0.7))\n",
    "model.add(TemporalMeanPooling())\n",
    "model.add(Dense(2, activation='softmax', name='dense_final'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 300)           1388400   \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "temporal_mean_pooling_35 (Te (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_final (Dense)          (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,549,002\n",
      "Trainable params: 1,549,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['acc']) ##adam\n",
    "checkpoint = ModelCheckpoint('best_model.h5', verbose=-2, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.6901 - acc: 0.5038 - val_loss: 0.6697 - val_acc: 0.6132\n",
      "Epoch 2/25\n",
      "2/2 [==============================] - 1s 409ms/step - loss: 0.6786 - acc: 0.5928 - val_loss: 0.6763 - val_acc: 0.6132\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.6778 - acc: 0.5953 - val_loss: 0.6682 - val_acc: 0.6132\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 0.6747 - acc: 0.5953 - val_loss: 0.6667 - val_acc: 0.6132\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.6725 - acc: 0.5953 - val_loss: 0.6693 - val_acc: 0.6132\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.6719 - acc: 0.5959 - val_loss: 0.6676 - val_acc: 0.6132\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.6723 - acc: 0.5972 - val_loss: 0.6667 - val_acc: 0.6132\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.6675 - acc: 0.5953 - val_loss: 0.6778 - val_acc: 0.6132\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.6737 - acc: 0.6017 - val_loss: 0.6692 - val_acc: 0.6158\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.6636 - acc: 0.6004 - val_loss: 0.6767 - val_acc: 0.6132\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 1s 374ms/step - loss: 0.6466 - acc: 0.6099 - val_loss: 1.4687 - val_acc: 0.6132\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 1s 417ms/step - loss: 1.0320 - acc: 0.5997 - val_loss: 0.6738 - val_acc: 0.6081\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 1s 359ms/step - loss: 0.6514 - acc: 0.6061 - val_loss: 0.6694 - val_acc: 0.6158\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 1s 328ms/step - loss: 0.6380 - acc: 0.6061 - val_loss: 0.6710 - val_acc: 0.6132\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 0.6262 - acc: 0.6067 - val_loss: 0.6759 - val_acc: 0.6132\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 1s 327ms/step - loss: 0.6119 - acc: 0.6239 - val_loss: 0.6836 - val_acc: 0.5954\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.5996 - acc: 0.6557 - val_loss: 0.6843 - val_acc: 0.5369\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.5899 - acc: 0.6747 - val_loss: 0.6909 - val_acc: 0.4885\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 1s 422ms/step - loss: 0.6048 - acc: 0.6741 - val_loss: 0.7105 - val_acc: 0.4453\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 1s 366ms/step - loss: 0.6101 - acc: 0.6518 - val_loss: 0.7238 - val_acc: 0.5522\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 1s 422ms/step - loss: 0.5428 - acc: 0.7186 - val_loss: 0.7453 - val_acc: 0.5191\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 1s 584ms/step - loss: 0.5350 - acc: 0.7249 - val_loss: 0.7255 - val_acc: 0.4529\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.6191 - acc: 0.6785 - val_loss: 0.7441 - val_acc: 0.4148\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.6277 - acc: 0.6309 - val_loss: 0.6958 - val_acc: 0.5420\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 1s 326ms/step - loss: 0.5193 - acc: 0.7630 - val_loss: 0.7606 - val_acc: 0.5165\n",
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_softmax_train, validation_data=(x_val, y_softmax_val), epochs=25, batch_size=1024,shuffle=True, callbacks=[checkpoint])\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_pooling/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm_pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.71      0.81       933\n",
      "         1.0       0.69      0.92      0.79       641\n",
      "\n",
      "    accuracy                           0.80      1574\n",
      "   macro avg       0.81      0.82      0.80      1574\n",
      "weighted avg       0.83      0.80      0.80      1574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.48      0.55       241\n",
      "         1.0       0.41      0.57      0.48       152\n",
      "\n",
      "    accuracy                           0.52       393\n",
      "   macro avg       0.53      0.53      0.51       393\n",
      "weighted avg       0.55      0.52      0.52       393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_train)\n",
    "predictions = [np.argmax(i) for i in predictions ]\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_train, predictions))\n",
    "\n",
    "predictions_val = model.predict(x_val)\n",
    "predictions_val = [np.argmax(i) for i in predictions_val ]\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_val, predictions_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "test_data_semeval = SemEvalData(MAX_WORD_NUM)\n",
    "test_data_semeval.load_data(\"data/tsd_trial.csv\")\n",
    "test_df_preprocessed = test_data_semeval.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_df_preprocessed\n",
    "test_data = {\n",
    "    'sentence':  result.sentences.sum(),\n",
    "    'toxicity_sentence': result.toxicity_sentence.sum()\n",
    "        }\n",
    "\n",
    "test_df = pd.DataFrame (test_data, columns = ['sentence','toxicity_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"lstm_pooling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 300)           1388400   \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "temporal_mean_pooling_35 (Te (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_final (Dense)          (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,549,002\n",
      "Trainable params: 1,549,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting explanation to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "WARNING:tensorflow:From /home/patrycja/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/pipeline.py:464: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "[10, 11, 4, 5, 6, 7, 8, 44, 45, 46, 47, 48, 49]\n",
      "[24, 25, 26, 27, 29, 30, 31, 32, 33, 57, 58, 59, 60, 61, 62, 63]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-9b7c0a1c54d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_span_lstm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_lime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-221-9b7c0a1c54d5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_span_lstm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_lime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Repositories/wedt-project/test_sentence.py\u001b[0m in \u001b[0;36mtest_lime\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mtext_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;31m#print(text_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mtoxic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPredictedWordsFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mtoxic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoxic_words\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoxic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Repositories/wedt-project/test_sentence.py\u001b[0m in \u001b[0;36mgetPredictedWordsFromSentence\u001b[0;34m(sentence, threshold, c)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NoToxic\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Toxic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mpredicted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mexpWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mmaxScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                         mask_string=self.mask_string))\n\u001b[1;32m    412\u001b[0m         \u001b[0mdomain_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDomainMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         data, yss, distances = self.__data_labels_distances(\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mindexed_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             distance_metric=distance_metric)\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minactive\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_removing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \"\"\"\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m       logging.warning('Network returning invalid probability values. '\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_df_preprocessed[\"predicted_span_lstm\"]=[test_lime(sentences) for sentences in test_df_preprocessed[\"original_text\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\julia\\desktop\\wedt\\wedt-project\\env\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_df_preprocessed[\"Pscore_lstm\"] = [ 1 if (len(s) == 0 and len(ps) == 0) \n",
    "                             else 0 if len(ps) == 0 \n",
    "                             else len( set(s).intersection(set(ps) ))/ len(set(ps))  for s, ps in zip(test_df_preprocessed[\"spans\"],test_df_preprocessed[\"predicted_span_lstm\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\julia\\desktop\\wedt\\wedt-project\\env\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_df_preprocessed[\"Rscore_lstm\"] = [ 1 if (len(s) == 0 and len(ps) == 0) \n",
    "                             else 0 if len(s) == 0 \n",
    "                             else len( set(s).intersection(set(ps) ))/ len(set(s))  for s, ps in zip(test_df_preprocessed[\"spans\"],test_df_preprocessed[\"predicted_span_lstm\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\julia\\desktop\\wedt\\wedt-project\\env\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_df_preprocessed[\"Fscore_lstm\"] = [ 0 if (p == 0 and r == 0)\n",
    "    else 2 * p *r /(p + r) for p, r in zip(test_df_preprocessed[\"Pscore_lstm\"], test_df_preprocessed[\"Rscore_lstm\"] )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxic_words</th>\n",
       "      <th>original_text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>diff</th>\n",
       "      <th>toxicity_sentence</th>\n",
       "      <th>predicted_span</th>\n",
       "      <th>Pscore</th>\n",
       "      <th>Rscore</th>\n",
       "      <th>Fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>because hes a moron and a bigot. its not any m...</td>\n",
       "      <td>1</td>\n",
       "      <td>[moron, bigot]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "      <td>[because hes a moron and a bigot., its not any...</td>\n",
       "      <td>[10, 36]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[8, 9, 10, 11, 27, 28, 29, 30, 31, 21, 22, 23,...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>how about we stop protecting idiots and let na...</td>\n",
       "      <td>1</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "      <td>[how about we stop protecting idiots and let n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0, 1, 2, 10, 11, 13, 14, 15, 16, 18, 19, 20, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>if people  were  smart, they would  boycott th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[idiots]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "      <td>[if people  were  smart, they would  boycott t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>trump claimed that russia will never invade th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "      <td>[trump claimed that russia will never invade t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>as long as your willing to pay a lot more for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "      <td>[as long as your willing to pay a lot more for...</td>\n",
       "      <td>[148]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[177, 178, 179, 180, 167, 168, 170, 171, 172, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[8, 9, 10, 11, 12]</td>\n",
       "      <td>only an idiot would use and believe anything t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>Only an idiot would use and believe anything t...</td>\n",
       "      <td>[only an idiot would use and believe anything ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[14, 15, 16, 17, 18, 8, 9, 10, 11, 12, 28, 29,...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[265, 266, 267, 268, 269, 270, 271, 272, 273, ...</td>\n",
       "      <td>thanks a lot douchebag. youre the reason the p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[o try to turn salem into some kind of new-stu...</td>\n",
       "      <td>Thanks a lot douchebag. You're the reason the ...</td>\n",
       "      <td>[thanks a lot douchebag., youre the reason the...</td>\n",
       "      <td>[27, 467]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "      <td>kick all the non human criminal illegals out o...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>kick all the non human criminal illegals out o...</td>\n",
       "      <td>[kick all the non human criminal illegals out ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[38, 39, 40, 41, 42, 43]</td>\n",
       "      <td>because driving under ontario laws is stupid e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[stupid]</td>\n",
       "      <td>Because driving under Ontario laws is stupid e...</td>\n",
       "      <td>[because driving under ontario laws is stupid ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[45, 46, 47, 48, 49, 50]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[277, 278, 279, 280, 281, 282, 283, 284, 285, ...</td>\n",
       "      <td>youre wrong.  the delay between retirement and...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dont make ignorant statements]</td>\n",
       "      <td>You're wrong.  The delay between retirement an...</td>\n",
       "      <td>[youre wrong., the delay between retirement an...</td>\n",
       "      <td>[3, 264, 280]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[26, 27, 28, 29, 30]</td>\n",
       "      <td>billy, are you a complete idiot, being thick h...</td>\n",
       "      <td>1</td>\n",
       "      <td>[idiot]</td>\n",
       "      <td>Billy, are you a complete idiot, being thick h...</td>\n",
       "      <td>[billy, are you a complete idiot, being thick ...</td>\n",
       "      <td>[245]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[177, 178, 179, 180, 181, 182, 183, 184, 185, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51, 5...</td>\n",
       "      <td>trump said, in as many words, that mexicans we...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mexicans, rapists, drug dealers]</td>\n",
       "      <td>Trump said, IN AS MANY WORDS, that Mexicans we...</td>\n",
       "      <td>[trump said, in as many words, that mexicans w...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[23, 24, 25, 26, 27]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16]</td>\n",
       "      <td>hes a psychopath.</td>\n",
       "      <td>1</td>\n",
       "      <td>[psychopath]</td>\n",
       "      <td>He's a psychopath.</td>\n",
       "      <td>[hes a psychopath.]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[]</td>\n",
       "      <td>clinton should be the last person to say anyth...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Clinton should be the last person to say anyth...</td>\n",
       "      <td>[clinton should be the last person to say anyt...</td>\n",
       "      <td>[99, 415, 467]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[133, 134, 168, 169, 170, 171, 172, 173, 174, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[23, 24, 25, 26]</td>\n",
       "      <td>people insist on being dumb. no other explanat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dumb]</td>\n",
       "      <td>People insist on being dumb. No other explanat...</td>\n",
       "      <td>[people insist on being dumb., no other explan...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[]</td>\n",
       "      <td>canadians killed by islamic extremists? the im...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Canadians killed by Islamic extremists? The im...</td>\n",
       "      <td>[canadians killed by islamic extremists?, the ...</td>\n",
       "      <td>[462]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[444, 445, 446, 447, 448]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[51, 52, 53, 54, 55, 56, 57, 58, 59]</td>\n",
       "      <td>so next year if you apply for yours, then your...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hypocrite]</td>\n",
       "      <td>So next year if you apply for yours, then you'...</td>\n",
       "      <td>[so next year if you apply for yours, then you...</td>\n",
       "      <td>[45]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[103, 104, 105, 106, 107, 108, 109, 110, 111, ...</td>\n",
       "      <td>this new has made the a/p, cnbc, bloomberg,  e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ridiculous]</td>\n",
       "      <td>This new has made the A/P, CNBC, Bloomberg,  e...</td>\n",
       "      <td>[this new has made the a/p, cnbc, bloomberg,  ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                spans  \\\n",
       "0            [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                            [29, 30, 31, 32, 33, 34]   \n",
       "2                      [166, 167, 168, 169, 170, 171]   \n",
       "3                            [87, 88, 89, 90, 91, 92]   \n",
       "4                                                  []   \n",
       "5                                  [8, 9, 10, 11, 12]   \n",
       "6   [265, 266, 267, 268, 269, 270, 271, 272, 273, ...   \n",
       "7                                                  []   \n",
       "8                            [38, 39, 40, 41, 42, 43]   \n",
       "9   [277, 278, 279, 280, 281, 282, 283, 284, 285, ...   \n",
       "10                               [26, 27, 28, 29, 30]   \n",
       "11  [35, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51, 5...   \n",
       "12              [7, 8, 9, 10, 11, 12, 13, 14, 15, 16]   \n",
       "13                                                 []   \n",
       "14                                   [23, 24, 25, 26]   \n",
       "15                                                 []   \n",
       "16               [51, 52, 53, 54, 55, 56, 57, 58, 59]   \n",
       "17  [103, 104, 105, 106, 107, 108, 109, 110, 111, ...   \n",
       "\n",
       "                                                 text  toxicity  \\\n",
       "0   because hes a moron and a bigot. its not any m...         1   \n",
       "1   how about we stop protecting idiots and let na...         1   \n",
       "2   if people  were  smart, they would  boycott th...         1   \n",
       "3   trump claimed that russia will never invade th...         1   \n",
       "4   as long as your willing to pay a lot more for ...         0   \n",
       "5   only an idiot would use and believe anything t...         1   \n",
       "6   thanks a lot douchebag. youre the reason the p...         1   \n",
       "7   kick all the non human criminal illegals out o...         0   \n",
       "8   because driving under ontario laws is stupid e...         1   \n",
       "9   youre wrong.  the delay between retirement and...         1   \n",
       "10  billy, are you a complete idiot, being thick h...         1   \n",
       "11  trump said, in as many words, that mexicans we...         1   \n",
       "12                                  hes a psychopath.         1   \n",
       "13  clinton should be the last person to say anyth...         0   \n",
       "14  people insist on being dumb. no other explanat...         1   \n",
       "15  canadians killed by islamic extremists? the im...         0   \n",
       "16  so next year if you apply for yours, then your...         1   \n",
       "17  this new has made the a/p, cnbc, bloomberg,  e...         1   \n",
       "\n",
       "                                          toxic_words  \\\n",
       "0                                      [moron, bigot]   \n",
       "1                                            [idiots]   \n",
       "2                                            [idiots]   \n",
       "3                                            [stupid]   \n",
       "4                                                  []   \n",
       "5                                             [idiot]   \n",
       "6   [o try to turn salem into some kind of new-stu...   \n",
       "7                                                  []   \n",
       "8                                            [stupid]   \n",
       "9                     [dont make ignorant statements]   \n",
       "10                                            [idiot]   \n",
       "11                  [mexicans, rapists, drug dealers]   \n",
       "12                                       [psychopath]   \n",
       "13                                                 []   \n",
       "14                                             [dumb]   \n",
       "15                                                 []   \n",
       "16                                        [hypocrite]   \n",
       "17                                       [ridiculous]   \n",
       "\n",
       "                                        original_text  \\\n",
       "0   Because he's a moron and a bigot. It's not any...   \n",
       "1   How about we stop protecting idiots and let na...   \n",
       "2   If people  were  smart, they would  Boycott th...   \n",
       "3   Trump Claimed that Russia will never invade th...   \n",
       "4   As long as your willing to pay a lot more for ...   \n",
       "5   Only an idiot would use and believe anything t...   \n",
       "6   Thanks a lot douchebag. You're the reason the ...   \n",
       "7   kick all the non human criminal illegals out o...   \n",
       "8   Because driving under Ontario laws is stupid e...   \n",
       "9   You're wrong.  The delay between retirement an...   \n",
       "10  Billy, are you a complete idiot, being thick h...   \n",
       "11  Trump said, IN AS MANY WORDS, that Mexicans we...   \n",
       "12                                 He's a psychopath.   \n",
       "13  Clinton should be the last person to say anyth...   \n",
       "14  People insist on being dumb. No other explanat...   \n",
       "15  Canadians killed by Islamic extremists? The im...   \n",
       "16  So next year if you apply for yours, then you'...   \n",
       "17  This new has made the A/P, CNBC, Bloomberg,  e...   \n",
       "\n",
       "                                            sentences            diff  \\\n",
       "0   [because hes a moron and a bigot., its not any...        [10, 36]   \n",
       "1   [how about we stop protecting idiots and let n...              []   \n",
       "2   [if people  were  smart, they would  boycott t...              []   \n",
       "3   [trump claimed that russia will never invade t...              []   \n",
       "4   [as long as your willing to pay a lot more for...           [148]   \n",
       "5   [only an idiot would use and believe anything ...              []   \n",
       "6   [thanks a lot douchebag., youre the reason the...       [27, 467]   \n",
       "7   [kick all the non human criminal illegals out ...              []   \n",
       "8   [because driving under ontario laws is stupid ...              []   \n",
       "9   [youre wrong., the delay between retirement an...   [3, 264, 280]   \n",
       "10  [billy, are you a complete idiot, being thick ...           [245]   \n",
       "11  [trump said, in as many words, that mexicans w...              []   \n",
       "12                                [hes a psychopath.]             [2]   \n",
       "13  [clinton should be the last person to say anyt...  [99, 415, 467]   \n",
       "14  [people insist on being dumb., no other explan...              []   \n",
       "15  [canadians killed by islamic extremists?, the ...           [462]   \n",
       "16  [so next year if you apply for yours, then you...            [45]   \n",
       "17  [this new has made the a/p, cnbc, bloomberg,  ...              []   \n",
       "\n",
       "                                    toxicity_sentence  \\\n",
       "0                                          [1.0, 0.0]   \n",
       "1                                          [1.0, 0.0]   \n",
       "2                                               [1.0]   \n",
       "3                                               [1.0]   \n",
       "4                                     [0.0, 0.0, 0.0]   \n",
       "5                                               [1.0]   \n",
       "6                 [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]   \n",
       "7                                               [0.0]   \n",
       "8                                               [1.0]   \n",
       "9                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "10  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "11                                              [1.0]   \n",
       "12                                              [1.0]   \n",
       "13           [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "14                                         [1.0, 0.0]   \n",
       "15                          [0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "16                                              [1.0]   \n",
       "17           [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                       predicted_span    Pscore  Rscore  \\\n",
       "0   [8, 9, 10, 11, 27, 28, 29, 30, 31, 21, 22, 23,...  0.588235     1.0   \n",
       "1   [0, 1, 2, 10, 11, 13, 14, 15, 16, 18, 19, 20, ...  0.000000     0.0   \n",
       "2                                                  []  0.000000     0.0   \n",
       "3                                                  []  0.000000     0.0   \n",
       "4   [177, 178, 179, 180, 167, 168, 170, 171, 172, ...  0.000000     0.0   \n",
       "5   [14, 15, 16, 17, 18, 8, 9, 10, 11, 12, 28, 29,...  0.200000     1.0   \n",
       "6   [0, 1, 2, 3, 4, 5, 13, 14, 15, 16, 17, 18, 19,...  0.000000     0.0   \n",
       "7                                                  []  1.000000     1.0   \n",
       "8                            [45, 46, 47, 48, 49, 50]  0.000000     0.0   \n",
       "9                                                  []  0.000000     0.0   \n",
       "10  [177, 178, 179, 180, 181, 182, 183, 184, 185, ...  0.000000     0.0   \n",
       "11                               [23, 24, 25, 26, 27]  0.000000     0.0   \n",
       "12                                       [0, 1, 2, 3]  0.000000     0.0   \n",
       "13  [133, 134, 168, 169, 170, 171, 172, 173, 174, ...  0.000000     0.0   \n",
       "14    [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 29, 30]  0.000000     0.0   \n",
       "15                          [444, 445, 446, 447, 448]  0.000000     0.0   \n",
       "16                                           [13, 14]  0.000000     0.0   \n",
       "17                                                 []  0.000000     0.0   \n",
       "\n",
       "      Fscore  \n",
       "0   0.740741  \n",
       "1   0.000000  \n",
       "2   0.000000  \n",
       "3   0.000000  \n",
       "4   0.000000  \n",
       "5   0.333333  \n",
       "6   0.000000  \n",
       "7   1.000000  \n",
       "8   0.000000  \n",
       "9   0.000000  \n",
       "10  0.000000  \n",
       "11  0.000000  \n",
       "12  0.000000  \n",
       "13  0.000000  \n",
       "14  0.000000  \n",
       "15  0.000000  \n",
       "16  0.000000  \n",
       "17  0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_score= np.mean(test_df_preprocessed[\"Fscore_lstm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11522633744855969"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patrycja/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/pipeline.py:464: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "[8, 9, 10, 11, 0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[11,33] = 8983 is not in [0, 4628)\n\t [[node sequential_46/embedding/embedding_lookup (defined at /home/patrycja/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/pipeline.py:464) ]] [Op:__inference_predict_function_27686]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_46/embedding/embedding_lookup:\n sequential_46/embedding/embedding_lookup/27419 (defined at /home/patrycja/anaconda3/envs/w2w/lib/python3.8/contextlib.py:113)\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8a1f7d201834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_span_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_lime_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-8a1f7d201834>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_span_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_lime_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_df_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Repositories/wedt-project/test_sentence.py\u001b[0m in \u001b[0;36mtest_lime_2\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mtext_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m#print(text_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtoxic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPredictedWordsFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRESHOLD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mtoxic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoxic_words\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoxic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Repositories/wedt-project/test_sentence.py\u001b[0m in \u001b[0;36mgetPredictedWordsFromSentence\u001b[0;34m(sentence, threshold, c)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NoToxic\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Toxic\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mpredicted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mexpWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mmaxScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                         mask_string=self.mask_string))\n\u001b[1;32m    412\u001b[0m         \u001b[0mdomain_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDomainMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         data, yss, distances = self.__data_labels_distances(\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mindexed_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             distance_metric=distance_metric)\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minactive\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_removing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \"\"\"\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m       logging.warning('Network returning invalid probability values. '\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/w2w/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[11,33] = 8983 is not in [0, 4628)\n\t [[node sequential_46/embedding/embedding_lookup (defined at /home/patrycja/anaconda3/envs/w2w/lib/python3.8/site-packages/sklearn/pipeline.py:464) ]] [Op:__inference_predict_function_27686]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_46/embedding/embedding_lookup:\n sequential_46/embedding/embedding_lookup/27419 (defined at /home/patrycja/anaconda3/envs/w2w/lib/python3.8/contextlib.py:113)\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "test_df_preprocessed[\"predicted_span_at\"]=[test_lime_2(sentences) for sentences in test_df_preprocessed[\"original_text\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preprocessed[\"Pscore_at\"] = [ 1 if (len(s) == 0 and len(ps) == 0) \n",
    "                             else 0 if len(ps) == 0 \n",
    "                             else len( set(s).intersection(set(ps) ))/ len(set(ps))  for s, ps in zip(test_df_preprocessed[\"spans\"],test_df_preprocessed[\"predicted_span_at\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preprocessed[\"Rscore_at\"] = [ 1 if (len(s) == 0 and len(ps) == 0) \n",
    "                             else 0 if len(s) == 0 \n",
    "                             else len( set(s).intersection(set(ps) ))/ len(set(s))  for s, ps in zip(test_df_preprocessed[\"spans\"],test_df_preprocessed[\"predicted_span_at\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_preprocessed[\"Fscore_at\"] = [ 0 if (p == 0 and r == 0)\n",
    "    else 2 * p *r /(p + r) for p, r in zip(test_df_preprocessed[\"Pscore_at\"], test_df_preprocessed[\"Rscore_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_score= np.mean(test_df_preprocessed[\"Fscore_at\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-197-568d6d9acfdb>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(x_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=20, random_state=0)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.86      0.87       933\n",
      "         1.0       0.80      0.81      0.81       641\n",
      "\n",
      "    accuracy                           0.84      1574\n",
      "   macro avg       0.84      0.84      0.84      1574\n",
      "weighted avg       0.84      0.84      0.84      1574\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.62      0.62       241\n",
      "         1.0       0.40      0.40      0.40       152\n",
      "\n",
      "    accuracy                           0.54       393\n",
      "   macro avg       0.51      0.51      0.51       393\n",
      "weighted avg       0.54      0.54      0.54       393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_train)\n",
    "predictions = [np.argmax(i) for i in predictions ]\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_train, predictions))\n",
    "\n",
    "predictions_val = model.predict(x_val)\n",
    "predictions_val = [np.argmax(i) for i in predictions_val ]\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_val, predictions_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
